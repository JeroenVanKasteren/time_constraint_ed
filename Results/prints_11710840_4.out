Rounded t down to nearest multiple of 1/gamma.
J = 2 , D = 65 , s = 8 , gamma = 25.0 , (P= 1000.0 ) , load= 0.6674 
 lambda: [1.3982 2.8804] 
 mu: [0.8639 0.774 ] 
 Target: [1. 1.] 
 r: [1. 1.] 
 c: [1. 1.] 
 s_star: [2.6157 5.3843] 
 rho: [0.6187 0.6911] 
 P(W>D): [0.05263594 0.01977517] 
 Weighted cap_prob: 0.0305 
 W:  0.0085 GB. 
 V:  0.0028 GB.
iter:  0 inner_iter:  -1 , delta:  0.88 , D_min 0.0 , D_max 0.88 , g:  25.0
iter:  100 inner_iter:  -1 , delta:  0.0 , D_min 0.07 , D_max 0.08 , g:  4.2015
iter:  200 inner_iter:  -1 , delta:  0.0 , D_min 0.07 , D_max 0.08 , g:  4.2672
iter:  300 inner_iter:  -1 , delta:  0.0 , D_min 0.07 , D_max 0.08 , g:  4.2829
iter:  400 inner_iter:  -1 , delta:  0.0 , D_min 0.08 , D_max 0.08 , g:  4.2873
iter:  500 inner_iter:  -1 , delta:  0.0 , D_min 0.08 , D_max 0.08 , g:  4.2885
iter:  600 inner_iter:  -1 , delta:  0.0 , D_min 0.08 , D_max 0.08 , g:  4.2889
iter:  700 inner_iter:  -1 , delta:  0.0 , D_min 0.08 , D_max 0.08 , g:  4.2891
iter:  800 inner_iter:  -1 , delta:  0.0 , D_min 0.08 , D_max 0.08 , g:  4.289
iter:  900 inner_iter:  -1 , delta:  0.0 , D_min 0.08 , D_max 0.08 , g:  4.2889
iter:  930 inner_iter:  -1 , delta:  0.0 , D_min 0.08 , D_max 0.08 , g:  4.289
Value Iteration converged in 930 iterations. g= 4.289
iter:  0 inner_iter:  0 , delta:  2.41 , D_min 0.08 , D_max 2.49 , g:  72.9438
iter:  0 inner_iter:  100 , delta:  0.0 , D_min 0.07 , D_max 0.08 , g:  4.2199
iter:  0 inner_iter:  200 , delta:  0.0 , D_min 0.07 , D_max 0.07 , g:  4.1906
iter:  0 inner_iter:  300 , delta:  0.0 , D_min 0.07 , D_max 0.07 , g:  4.174
iter:  0 inner_iter:  400 , delta:  0.0 , D_min 0.07 , D_max 0.07 , g:  4.166
iter:  0 inner_iter:  500 , delta:  0.0 , D_min 0.07 , D_max 0.07 , g:  4.1618
iter:  0 inner_iter:  600 , delta:  0.0 , D_min 0.07 , D_max 0.07 , g:  4.1594
iter:  0 inner_iter:  700 , delta:  0.0 , D_min 0.07 , D_max 0.07 , g:  4.1581
iter:  0 inner_iter:  800 , delta:  0.0 , D_min 0.07 , D_max 0.07 , g:  4.1574
iter:  0 inner_iter:  900 , delta:  0.0 , D_min 0.07 , D_max 0.07 , g:  4.157
iter:  0 inner_iter:  1000 , delta:  0.0 , D_min 0.07 , D_max 0.07 , g:  4.1568
iter:  0 inner_iter:  1100 , delta:  0.0 , D_min 0.07 , D_max 0.07 , g:  4.1567
iter:  0 inner_iter:  1200 , delta:  0.0 , D_min 0.07 , D_max 0.07 , g:  4.1567
iter:  0 inner_iter:  1300 , delta:  0.0 , D_min 0.07 , D_max 0.07 , g:  4.1567
iter:  0 inner_iter:  1400 , delta:  0.0 , D_min 0.07 , D_max 0.07 , g:  4.1567
iter:  0 inner_iter:  1440 , delta:  0.0 , D_min 0.07 , D_max 0.07 , g:  4.1566
One-step Policy Improvement converged in 1440 iterations. g= 4.1566
