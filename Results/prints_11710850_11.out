Rounded t down to nearest multiple of 1/gamma.
J = 2 , D = 149 , s = 6 , gamma = 25.0 , (P= 1000.0 ) , load= 0.7497 
 lambda: [2.8    0.2826] 
 mu: [0.7847 0.3038] 
 Target: [1. 1.] 
 r: [1. 1.] 
 c: [1. 1.] 
 s_star: [5.0691 0.9309] 
 rho: [0.7039 0.9989] 
 P(W>D): [8.38352612e-04 9.97194978e-01] 
 Weighted cap_prob: 0.0922 
 W:  0.0265 GB. 
 V:  0.0088 GB.
iter:  0 inner_iter:  -1 , delta:  0.91 , D_min 0.0 , D_max 0.91 , g:  25.0
iter:  100 inner_iter:  -1 , delta:  0.05 , D_min 0.01 , D_max 0.05 , g:  1.7515
iter:  200 inner_iter:  -1 , delta:  0.03 , D_min 0.02 , D_max 0.05 , g:  2.0083
iter:  300 inner_iter:  -1 , delta:  0.02 , D_min 0.03 , D_max 0.05 , g:  2.2418
iter:  400 inner_iter:  -1 , delta:  0.01 , D_min 0.04 , D_max 0.05 , g:  2.5295
iter:  500 inner_iter:  -1 , delta:  0.01 , D_min 0.05 , D_max 0.05 , g:  2.6876
iter:  600 inner_iter:  -1 , delta:  0.0 , D_min 0.05 , D_max 0.05 , g:  2.7631
iter:  700 inner_iter:  -1 , delta:  0.0 , D_min 0.05 , D_max 0.05 , g:  2.807
iter:  800 inner_iter:  -1 , delta:  0.0 , D_min 0.05 , D_max 0.05 , g:  2.8338
iter:  900 inner_iter:  -1 , delta:  0.0 , D_min 0.05 , D_max 0.05 , g:  2.8492
iter:  1000 inner_iter:  -1 , delta:  0.0 , D_min 0.05 , D_max 0.05 , g:  2.8576
iter:  1100 inner_iter:  -1 , delta:  0.0 , D_min 0.05 , D_max 0.05 , g:  2.863
iter:  1200 inner_iter:  -1 , delta:  0.0 , D_min 0.05 , D_max 0.05 , g:  2.8658
iter:  1300 inner_iter:  -1 , delta:  0.0 , D_min 0.05 , D_max 0.05 , g:  2.8681
iter:  1400 inner_iter:  -1 , delta:  0.0 , D_min 0.05 , D_max 0.05 , g:  2.8699
Value Iteration iter: 1430 ( -1 ) reached max_time = True , g~ 2.8703
iter:  0 inner_iter:  0 , delta:  2.6 , D_min 0.06 , D_max 2.66 , g:  74.3298
One-step Policy Improvement iter: 0 ( 0 ) reached max_time = True , g~ 74.3298
