Rounded t down to nearest multiple of 1/gamma.
J = 2 , D = 94 , s = 5 , gamma = 25.0 , (P= 1000.0 ) , load= 0.5702 
 lambda: [0.8585 1.0522] 
 mu: [0.8852 0.5594] 
 Target: [1. 1.] 
 r: [1. 1.] 
 c: [1. 1.] 
 s_star: [1.8982 3.1018] 
 rho: [0.511  0.6065] 
 P(W>D): [0.01934266 0.03204134] 
 Weighted cap_prob: 0.0263 
 W:  0.0078 GB. 
 V:  0.0026 GB.
iter:  0 inner_iter:  -1 , delta:  0.92 , D_min 0.0 , D_max 0.92 , g:  25.0
iter:  100 inner_iter:  -1 , delta:  0.01 , D_min 0.03 , D_max 0.03 , g:  1.7276
iter:  200 inner_iter:  -1 , delta:  0.0 , D_min 0.03 , D_max 0.03 , g:  1.786
iter:  300 inner_iter:  -1 , delta:  0.0 , D_min 0.03 , D_max 0.03 , g:  1.8117
iter:  400 inner_iter:  -1 , delta:  0.0 , D_min 0.03 , D_max 0.03 , g:  1.824
iter:  500 inner_iter:  -1 , delta:  0.0 , D_min 0.03 , D_max 0.03 , g:  1.8303
iter:  600 inner_iter:  -1 , delta:  0.0 , D_min 0.03 , D_max 0.03 , g:  1.8335
iter:  700 inner_iter:  -1 , delta:  0.0 , D_min 0.03 , D_max 0.03 , g:  1.8352
iter:  800 inner_iter:  -1 , delta:  0.0 , D_min 0.03 , D_max 0.03 , g:  1.8361
iter:  900 inner_iter:  -1 , delta:  0.0 , D_min 0.03 , D_max 0.03 , g:  1.8366
iter:  1000 inner_iter:  -1 , delta:  0.0 , D_min 0.03 , D_max 0.03 , g:  1.8369
iter:  1100 inner_iter:  -1 , delta:  0.0 , D_min 0.03 , D_max 0.03 , g:  1.8369
iter:  1200 inner_iter:  -1 , delta:  0.0 , D_min 0.03 , D_max 0.03 , g:  1.8369
iter:  1240 inner_iter:  -1 , delta:  0.0 , D_min 0.03 , D_max 0.03 , g:  1.8369
Value Iteration converged in 1240 iterations. g= 1.8369
iter:  0 inner_iter:  0 , delta:  1.97 , D_min 0.04 , D_max 2.0 , g:  55.3985
iter:  0 inner_iter:  100 , delta:  0.0 , D_min 0.03 , D_max 0.03 , g:  1.7897
iter:  0 inner_iter:  200 , delta:  0.0 , D_min 0.03 , D_max 0.03 , g:  1.8009
iter:  0 inner_iter:  300 , delta:  0.0 , D_min 0.03 , D_max 0.03 , g:  1.8059
iter:  0 inner_iter:  400 , delta:  0.0 , D_min 0.03 , D_max 0.03 , g:  1.8068
iter:  0 inner_iter:  500 , delta:  0.0 , D_min 0.03 , D_max 0.03 , g:  1.808
iter:  0 inner_iter:  600 , delta:  0.0 , D_min 0.03 , D_max 0.03 , g:  1.8089
iter:  0 inner_iter:  700 , delta:  0.0 , D_min 0.03 , D_max 0.03 , g:  1.8095
iter:  0 inner_iter:  800 , delta:  0.0 , D_min 0.03 , D_max 0.03 , g:  1.8099
iter:  0 inner_iter:  900 , delta:  0.0 , D_min 0.03 , D_max 0.03 , g:  1.8101
iter:  0 inner_iter:  1000 , delta:  0.0 , D_min 0.03 , D_max 0.03 , g:  1.8103
iter:  0 inner_iter:  1100 , delta:  0.0 , D_min 0.03 , D_max 0.03 , g:  1.8102
iter:  0 inner_iter:  1200 , delta:  0.0 , D_min 0.03 , D_max 0.03 , g:  1.8103
iter:  0 inner_iter:  1260 , delta:  0.0 , D_min 0.03 , D_max 0.03 , g:  1.8103
One-step Policy Improvement converged in 1260 iterations. g= 1.8103
