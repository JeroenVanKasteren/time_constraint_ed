Rounded t down to nearest multiple of 1/gamma.
J = 2 , D = 172 , s = 8 , gamma = 25.0 , (P= 1000.0 ) , load= 0.7133 
 lambda: [0.7313 1.344 ] 
 mu: [0.2681 0.4513] 
 Target: [1. 1.] 
 r: [1. 1.] 
 c: [1. 1.] 
 s_star: [3.583 4.417] 
 rho: [0.7615 0.6743] 
 P(W>D): [0.12151421 0.00575457] 
 Weighted cap_prob: 0.0465 
 W:  0.0582 GB. 
 V:  0.0194 GB.
iter:  0 inner_iter:  -1 , delta:  0.93 , D_min 0.0 , D_max 0.93 , g:  25.0
iter:  100 inner_iter:  -1 , delta:  0.02 , D_min 0.02 , D_max 0.04 , g:  1.6835
iter:  200 inner_iter:  -1 , delta:  0.01 , D_min 0.03 , D_max 0.04 , g:  1.7816
iter:  300 inner_iter:  -1 , delta:  0.01 , D_min 0.03 , D_max 0.04 , g:  1.8137
iter:  400 inner_iter:  -1 , delta:  0.01 , D_min 0.03 , D_max 0.04 , g:  1.8328
iter:  500 inner_iter:  -1 , delta:  0.0 , D_min 0.03 , D_max 0.04 , g:  1.8453
Value Iteration iter: 550 ( -1 ) reached max_time = True , g~ 1.8502
iter:  0 inner_iter:  0 , delta:  2.48 , D_min 0.04 , D_max 2.52 , g:  68.6819
One-step Policy Improvement iter: 0 ( 0 ) reached max_time = True , g~ 68.6819
