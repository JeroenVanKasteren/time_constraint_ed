Rounded t down to nearest multiple of 1/gamma.
J = 2 , D = 356 , s = 2 , gamma = 25.0 , (P= 1000.0 ) , load= 0.6814 
 lambda: [0.5062 0.4464] 
 mu: [0.876  0.5687] 
 Target: [1. 1.] 
 r: [1. 1.] 
 c: [1. 1.] 
 s_star: [0.9563 1.0437] 
 rho: [0.6043 0.752 ] 
 P(W>D): [0.00622606 0.09618257] 
 Weighted cap_prob: 0.0484 
 W:  0.0275 GB. 
 V:  0.0092 GB.
iter:  0 inner_iter:  -1 , delta:  0.97 , D_min 0.0 , D_max 0.97 , g:  25.0
iter:  100 inner_iter:  -1 , delta:  0.01 , D_min 0.0 , D_max 0.02 , g:  0.4573
iter:  200 inner_iter:  -1 , delta:  0.01 , D_min 0.0 , D_max 0.02 , g:  0.4887
iter:  300 inner_iter:  -1 , delta:  0.01 , D_min 0.01 , D_max 0.01 , g:  0.5158
iter:  400 inner_iter:  -1 , delta:  0.01 , D_min 0.01 , D_max 0.01 , g:  0.5383
iter:  500 inner_iter:  -1 , delta:  0.01 , D_min 0.01 , D_max 0.01 , g:  0.5593
iter:  600 inner_iter:  -1 , delta:  0.01 , D_min 0.01 , D_max 0.01 , g:  0.5788
iter:  700 inner_iter:  -1 , delta:  0.0 , D_min 0.01 , D_max 0.01 , g:  0.5927
iter:  800 inner_iter:  -1 , delta:  0.0 , D_min 0.01 , D_max 0.01 , g:  0.5937
iter:  900 inner_iter:  -1 , delta:  0.0 , D_min 0.01 , D_max 0.01 , g:  0.596
iter:  1000 inner_iter:  -1 , delta:  0.0 , D_min 0.01 , D_max 0.01 , g:  0.5999
iter:  1100 inner_iter:  -1 , delta:  0.0 , D_min 0.01 , D_max 0.01 , g:  0.6051
Value Iteration iter: 1120 ( -1 ) reached max_time = True , g~ 0.6063
iter:  0 inner_iter:  0 , delta:  1.94 , D_min 0.02 , D_max 1.96 , g:  51.2593
One-step Policy Improvement iter: 0 ( 0 ) reached max_time = True , g~ 51.2593
