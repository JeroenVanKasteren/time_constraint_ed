Rounded t down to nearest multiple of 1/gamma.
J = 2 , D = 63 , s = 9 , gamma = 25.0 , (P= 1000.0 ) , load= 0.4705 
 lambda: [0.3171 0.9489] 
 mu: [0.2708 0.3098] 
 Target: [1. 1.] 
 r: [1. 1.] 
 c: [1. 1.] 
 s_star: [2.8976 6.1024] 
 rho: [0.4041 0.502 ] 
 P(W>D): [0.04835188 0.01073295] 
 Weighted cap_prob: 0.0202 
 W:  0.0098 GB. 
 V:  0.0033 GB.
iter:  0 inner_iter:  -1 , delta:  0.95 , D_min 0.0 , D_max 0.95 , g:  25.0
iter:  100 inner_iter:  -1 , delta:  0.0 , D_min 0.02 , D_max 0.02 , g:  1.27
iter:  200 inner_iter:  -1 , delta:  0.0 , D_min 0.02 , D_max 0.02 , g:  1.2693
iter:  300 inner_iter:  -1 , delta:  0.0 , D_min 0.02 , D_max 0.02 , g:  1.2679
iter:  400 inner_iter:  -1 , delta:  0.0 , D_min 0.02 , D_max 0.02 , g:  1.2667
iter:  500 inner_iter:  -1 , delta:  0.0 , D_min 0.02 , D_max 0.02 , g:  1.2659
iter:  600 inner_iter:  -1 , delta:  0.0 , D_min 0.02 , D_max 0.02 , g:  1.2653
iter:  700 inner_iter:  -1 , delta:  0.0 , D_min 0.02 , D_max 0.02 , g:  1.265
iter:  800 inner_iter:  -1 , delta:  0.0 , D_min 0.02 , D_max 0.02 , g:  1.2647
iter:  900 inner_iter:  -1 , delta:  0.0 , D_min 0.02 , D_max 0.02 , g:  1.2646
iter:  1000 inner_iter:  -1 , delta:  0.0 , D_min 0.02 , D_max 0.02 , g:  1.2644
iter:  1100 inner_iter:  -1 , delta:  0.0 , D_min 0.02 , D_max 0.02 , g:  1.2643
iter:  1150 inner_iter:  -1 , delta:  0.0 , D_min 0.02 , D_max 0.02 , g:  1.2643
Value Iteration converged in 1150 iterations. g= 1.2643
iter:  0 inner_iter:  0 , delta:  1.76 , D_min 0.02 , D_max 1.79 , g:  47.8243
iter:  0 inner_iter:  100 , delta:  0.0 , D_min 0.02 , D_max 0.02 , g:  1.2582
iter:  0 inner_iter:  200 , delta:  0.0 , D_min 0.02 , D_max 0.02 , g:  1.2586
iter:  0 inner_iter:  300 , delta:  0.0 , D_min 0.02 , D_max 0.02 , g:  1.2578
iter:  0 inner_iter:  400 , delta:  0.0 , D_min 0.02 , D_max 0.02 , g:  1.2571
iter:  0 inner_iter:  500 , delta:  0.0 , D_min 0.02 , D_max 0.02 , g:  1.2565
iter:  0 inner_iter:  600 , delta:  0.0 , D_min 0.02 , D_max 0.02 , g:  1.2562
iter:  0 inner_iter:  700 , delta:  0.0 , D_min 0.02 , D_max 0.02 , g:  1.256
iter:  0 inner_iter:  800 , delta:  0.0 , D_min 0.02 , D_max 0.02 , g:  1.2559
iter:  0 inner_iter:  900 , delta:  0.0 , D_min 0.02 , D_max 0.02 , g:  1.2557
iter:  0 inner_iter:  1000 , delta:  0.0 , D_min 0.02 , D_max 0.02 , g:  1.2556
iter:  0 inner_iter:  1100 , delta:  0.0 , D_min 0.02 , D_max 0.02 , g:  1.2556
iter:  0 inner_iter:  1140 , delta:  0.0 , D_min 0.02 , D_max 0.02 , g:  1.2556
One-step Policy Improvement converged in 1140 iterations. g= 1.2556
